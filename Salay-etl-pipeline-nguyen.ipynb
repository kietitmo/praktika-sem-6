{"cells":[{"cell_type":"code","source":["# delte if delta lake exit\n# dbutils.fs.rm(delta_table_path,recurse=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"43a5712d-64c1-478d-9dbd-1e9448176a95","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[69]: True"]}],"execution_count":0},{"cell_type":"code","source":["# EXTRACT\n# Import the required libraries\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\nfrom delta import DeltaTable\n\n# Create SparkSession\nspark = SparkSession.builder.getOrCreate()\n\n# File location and type\nfile_location = \"/FileStore/tables/Salary_Data-8.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# Define the schema for the data\nschema = StructType([\n    StructField(\"Age\", IntegerType(), nullable=True),\n    StructField(\"Gender\", StringType(), nullable=True),\n    StructField(\"Education_Level\", StringType(), nullable=True),\n    StructField(\"Job_Title\", StringType(), nullable=True),\n    StructField(\"Years_of_Experience\", DoubleType(), nullable=True),\n    StructField(\"Salary\", DoubleType(), nullable=True)\n])\n\n# Read the CSV file into a DataFrame with defined schema\ndf = spark.read.format(file_type) \\\n    .schema(schema)\\\n    .option(\"inferSchema\", infer_schema) \\\n    .option(\"header\", first_row_is_header) \\\n    .option(\"sep\", delimiter) \\\n    .load(file_location)\n\n# Define the Delta table path\ndelta_table_path = \"/delta/salary_data\"\n\n# Write the DataFrame to Delta Lake with schema migration enabled\ndf.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n\n# Read the data from Delta Lake into a DataFrame\ndf = spark.read.format(\"delta\").load(delta_table_path)\n\ndf.describe().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0b24b12e-b135-49ed-bdd6-0dc401feffcc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+-----------------+------+---------------+---------------+-------------------+------------------+\n|summary|              Age|Gender|Education_Level|      Job_Title|Years_of_Experience|            Salary|\n+-------+-----------------+------+---------------+---------------+-------------------+------------------+\n|  count|             6702|  6702|           6701|           6702|               6701|              6699|\n|   mean|33.62085944494181|  null|           null|           null|  8.094687360095508|115326.96477086132|\n| stddev|7.614632626251299|  null|           null|           null|  6.059003056634108| 52786.18391068295|\n|    min|               21|Female|     Bachelor's|Account Manager|                0.0|             350.0|\n|    max|               62| Other|            phD|  Web Developer|               34.0|          250000.0|\n+-------+-----------------+------+---------------+---------------+-------------------+------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"83de9f4c-1162-4682-a6db-095b52c02650","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- Age: integer (nullable = true)\n |-- Gender: string (nullable = true)\n |-- Education_Level: string (nullable = true)\n |-- Job_Title: string (nullable = true)\n |-- Years_of_Experience: double (nullable = true)\n |-- Salary: double (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Count missing values of each column\nfrom pyspark.sql.functions import mean, last, col, count, when\n\ndf.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f2470bf0-f2b2-4b2d-9df2-e6a13316fa4d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+---------------+---------+-------------------+------+\n|Age|Gender|Education_Level|Job_Title|Years_of_Experience|Salary|\n+---+------+---------------+---------+-------------------+------+\n|  2|     2|              3|        2|                  3|     5|\n+---+------+---------------+---------+-------------------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# TRANSFRORM \n\n# Perform data processing on the DataFrame\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import mean, last, col, count, when, avg\n\n\n# Create SparkSession\nspark = SparkSession.builder.getOrCreate()\n\n# Handling missing values\n# Get means of columns 'Age', 'Years_of_Experience', 'Salary'\nmean_values = df.select(\n    mean('Age').alias('Age_mean'),\n    mean('Salary').alias('Salary_mean'),\n    mean('Years_of_Experience').alias('Years_of_Experience_mean')\n).first()\n\nage_mean = mean_values['Age_mean']\nyears_exp_mean = mean_values['Years_of_Experience_mean']\nsalary_mean = mean_values['Salary_mean']\n\nprint(years_exp_mean, salary_mean, age_mean)\n\n# Replace null value by mean in columns 'Age', 'Years_of_Experience', 'Salary'\ndf = df.fillna({'Age': age_mean, 'Years_of_Experience': years_exp_mean, 'Salary': salary_mean}, subset=['Age', 'Years_of_Experience', 'Salary'])\n\n# Get last value of column 'Gender', 'Education_Level', 'Job_Title'\nlast_row = df.agg(*[last(col_name).alias(col_name) for col_name in ['Gender', 'Education_Level', 'Job_Title']])\n\n# Replace null value by last value of each column\ndf = df.fillna(last_row.first().asDict(), subset=['Gender', 'Education_Level', 'Job_Title'])\n\n# show result\ndf.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4e6531ca-78b7-47d3-9ddc-b54bb1447603","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["8.094687360095508 115326.96477086132 33.62085944494181\n+---+------+---------------+---------+-------------------+------+\n|Age|Gender|Education_Level|Job_Title|Years_of_Experience|Salary|\n+---+------+---------------+---------+-------------------+------+\n|  0|     0|              0|        0|                  0|     0|\n+---+------+---------------+---------+-------------------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Perform average calculation on column \"Salary\"\naverage_salary = df.select(avg(col(\"Salary\"))).first()[0]\n\n# Create a new column \"Above Average Salary\" to highlight higher-than-average salaries\ndf = df.withColumn(\"Above_Average_Salary\", when(col(\"Salary\") > average_salary, 1).otherwise(0))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8da5c776-6359-45bc-84e8-9524d432d9e5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b17eacac-e3f2-4c16-b52a-b250764990d0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+---------------+--------------------+-------------------+--------+--------------------+\n|Age|Gender|Education_Level|           Job_Title|Years_of_Experience|  Salary|Above_Average_Salary|\n+---+------+---------------+--------------------+-------------------+--------+--------------------+\n| 32|  Male|     Bachelor's|   Software Engineer|                5.0| 90000.0|                   0|\n| 28|Female|       Master's|        Data Analyst|                3.0| 65000.0|                   0|\n| 45|  Male|            PhD|      Senior Manager|               15.0|150000.0|                   1|\n| 36|Female|     Bachelor's|     Sales Associate|                7.0| 60000.0|                   0|\n| 52|  Male|       Master's|            Director|               20.0|200000.0|                   1|\n| 29|  Male|     Bachelor's|   Marketing Analyst|                2.0| 55000.0|                   0|\n| 42|Female|       Master's|     Product Manager|               12.0|120000.0|                   1|\n| 31|  Male|     Bachelor's|       Sales Manager|                4.0| 80000.0|                   0|\n| 26|Female|     Bachelor's|Marketing Coordin...|                1.0| 45000.0|                   0|\n| 38|  Male|            PhD|    Senior Scientist|               10.0|110000.0|                   0|\n| 29|  Male|       Master's|  Software Developer|                3.0| 75000.0|                   0|\n| 48|Female|     Bachelor's|          HR Manager|               18.0|140000.0|                   1|\n| 35|  Male|     Bachelor's|   Financial Analyst|                6.0| 65000.0|                   0|\n| 40|Female|       Master's|     Project Manager|               14.0|130000.0|                   1|\n| 27|  Male|     Bachelor's|Customer Service Rep|                2.0| 40000.0|                   0|\n| 44|  Male|     Bachelor's|  Operations Manager|               16.0|125000.0|                   1|\n| 33|Female|       Master's|   Marketing Manager|                7.0| 90000.0|                   0|\n| 39|  Male|            PhD|     Senior Engineer|               12.0|115000.0|                   0|\n| 25|Female|     Bachelor's|    Data Entry Clerk|                0.0| 35000.0|                   0|\n| 51|  Male|     Bachelor's|      Sales Director|               22.0|180000.0|                   1|\n+---+------+---------------+--------------------+-------------------+--------+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(delta_table_path)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b24f41b9-7827-4bc1-a083-6987e1c2c1fb","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.printSchema()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0b304b97-84b8-4b1f-b469-45680606bc02","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- Age: integer (nullable = true)\n |-- Gender: string (nullable = false)\n |-- Education_Level: string (nullable = false)\n |-- Job_Title: string (nullable = false)\n |-- Years_of_Experience: double (nullable = false)\n |-- Salary: double (nullable = false)\n |-- Above_Average_Salary: integer (nullable = false)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["### LOAD\nimport datetime\n# Load data to PostgreSQL\ndriver = \"org.postgresql.Driver\"\nurl = \"jdbc:postgresql://dpg-cgcb7364dad7accgg5bg-a.frankfurt-postgres.render.com/kietitmo_db\"\ntable = \"practika\"\nuser = \"kietitmo_db_user\"\npassword = \"Ph1vwQz38o0LsO3yIRIIjdXzsHdsYodF\"\n\n# Get the current date\ncurrent_date = datetime.datetime.now().strftime(\"%Y%m%d\")\n\n# Construct the table name with the current date\ntable_name = f\"practika_{current_date}\"\n\n# Write the DataFrame to the dynamically named table\ndf.write.format(\"jdbc\") \\\n  .option(\"driver\", driver) \\\n  .option(\"url\", url) \\\n  .option(\"dbtable\", table_name) \\\n  .mode(\"append\") \\\n  .option(\"user\", user) \\\n  .option(\"password\", password) \\\n  .save()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"aaebf46a-a208-4a58-b77f-e06fca7f7f0e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Salay-etl-pipeline-nguyen","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
